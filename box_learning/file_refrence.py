class file_refrence:

	# These are the paths to the files
	##################################################
	pair_file_path = "data/pairs/"
	attachemnts_file_path = "data/attachments/"
	whole_question_path = 'data/problems/'
	new_annotation_path = 'data/prob_worlds/'
	whole_question_suffix = '_lemma.txt'
	question_strings_path = 'data/spilit/'
	ccg_parse_path = 'data/ccg_preprocessed/'
	gold_entity_path = 'data/entities_preprocessed/'
	gold_type_path = 'data/ans_preprocessed/'
	gold_chian_path = 'data/chains/'
	driven_chain_path = 'data/driven_chains/'
	np_pos_path = 'data/np_pos/'
	np_pos_path_entity = 'data/np_pos_entity/'
	question_string_nps_relevant_np_type_path = 'data/np_preprocessed_no_article/'
	question_string_nps_relevant_np_entity_path = 'data/np_preprocessed_no_article_entity/'
	relevant_pair_path = 'data/relevant_pair.txt'
	all_pairs_path = 'data/pairs.txt'
	non_relevant_pair_path = 'data/non_relevant_pairs.txt'
	relevant_np_entity_after_classifier = 'data/np_classifier_entity/'
	relevant_np_type_after_classifier = 'data/np_classifier/'
	question_string_np_before_article_ommiting = 'data/np_preprocessed/'
	merge_prob_path = 'data/merge_prob/'
	ilp_merge_results_path = 'data/ilp_merge_results/'
	ilp_merge_chain_res = 'data/ilp_merge_chains/'
	# question_string_np_before_article_ommiting_lemma = 'data/np_preprocessed/'
	# srl_path = 'data/easySrlOut.txt'
	gold_subset_type_pair_path = 'data/subset_types/'
	gold_subset_pair_paths = 'data/subsets/'
	gold_disjoint_type_pair_path = 'data/disjoint_types/'
	gold_disjoint_pair_path = 'data/disjoints/'
	gold_equivalence_type_pair_path = 'data/parallel_types/'
	gold_equivalence_pair_path = 'data/equivalence/'
	stan_parse_file_path = 'data/stan/'
	stan_dep_parse_tree_file_path = 'data/stan_dep/'
	stan_parse_story_file_path = 'data/stan/parse_stan_corenlp'
	pos_tagging_file_path = 'data/pos/'
	antonym_list_path = 'data/question-antonyms.dat'
	num_of_dimentions = 300
	synonym_list_path = 'data/we300.dat'
	score_file_name_relevant_np_entity = 's_nrop_entity.txt'
	score_file_name_relevant_np_entity_normalized = 's_np_entity_norm.txt'
	score_file_name_relevant_np_type = 's_np_type.txt'
	score_file_name_relevant_np_type_normalized = 's_np_type_norm.txt'
	score_file_name_relevant_pair = 's_pair.txt'
	score_file_name_relevant_pair_normaized = 's_pair_norm.txt'
	score_file_name_relevant_pair_parallel = 's_pair_par.txt'
	score_file_name_relevant_pair_parallel_normalized = 's_pair_par_norm.txt'
	score_file_name_join = 's_joint.txt'
	score_file_name_join_normalized = 's_joint_norm.txt'
	np_visualization_file_entity = 'data/np_visual_entity.txt'
	np_visualization_file_type = 'data/np_visual_type.txt'
	pair_visualize_data_file = 'data/pair_visual.txt'
	joint_visualize_data_file = 'data/joint_visual.txt'
	srl_file_path = 'data/srl/'


	###############################################

	#These are the lists of constants
	###############################################i == 283 or i == 308 or i == 312 or i == 335 or i == 375:
	problematic_indexes = [17, 30, 33, 70, 104, 106, 132, 151, 215, 246, 200, 281, 283, 308, 312, 335, 375]
	equivalence_relation_word_list = ['per', 'cost', 'equals', 'be', 'costs', 'equal', 'is', 'was', 'were', 'are', 'spend', 'spent', 'spends', 'for', 'a']
	equivalance_relation_per_like_rule_word_list = ['per', 'a']


	###############################################

	#These are the constant values
	###############################################
	num_of_dimentions = 300












